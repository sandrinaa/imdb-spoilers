{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T14:12:58.595349Z",
     "iopub.status.busy": "2025-11-30T14:12:58.593989Z",
     "iopub.status.idle": "2025-11-30T14:13:27.537819Z",
     "shell.execute_reply": "2025-11-30T14:13:27.536472Z",
     "shell.execute_reply.started": "2025-11-30T14:12:58.595299Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: contractions in /usr/local/lib/python3.11/dist-packages (0.1.73)\n",
      "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from contractions) (0.0.24)\n",
      "Requirement already satisfied: anyascii in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (0.3.3)\n",
      "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (2.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-30 14:13:14.656342: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1764511995.030590      99 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1764511995.130206      99 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'MessageFactory' object has no attribute 'GetPrototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"
     ]
    }
   ],
   "source": [
    "!pip install contractions\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "import re\n",
    "import html\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from keras.optimizers import Adam\n",
    "from collections import Counter\n",
    "from textblob import TextBlob\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, fbeta_score, roc_auc_score, classification_report, confusion_matrix, precision_recall_curve, roc_curve, auc, average_precision_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from scipy.sparse import hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T14:15:03.379012Z",
     "iopub.status.busy": "2025-11-30T14:15:03.378026Z",
     "iopub.status.idle": "2025-11-30T14:16:50.260878Z",
     "shell.execute_reply": "2025-11-30T14:16:50.259740Z",
     "shell.execute_reply.started": "2025-11-30T14:15:03.378971Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "train = pd.read_json(\"../data/processed/IMDB_reviews_train_cleaned.json\")\n",
    "test = pd.read_json(\"../data/processed/IMDB_reviews_test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T14:18:03.329150Z",
     "iopub.status.busy": "2025-11-30T14:18:03.328724Z",
     "iopub.status.idle": "2025-11-30T14:18:05.219748Z",
     "shell.execute_reply": "2025-11-30T14:18:05.218631Z",
     "shell.execute_reply.started": "2025-11-30T14:18:03.329118Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original joint counts:\n",
      " is_spoiler\n",
      "False    338256\n",
      "True     120868\n",
      "dtype: int64\n",
      "\n",
      "Target minimum sample size per joint group: 120868\n",
      "\n",
      "Target maximum sample size per joint group: 338256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99/2103583486.py:12: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  undersampled_train = train.groupby(['is_spoiler']).apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undersampled Train shape: (241736, 21)\n",
      "New joint counts:\n",
      " is_spoiler\n",
      "False    120868\n",
      "True     120868\n",
      "dtype: int64\n",
      "\n",
      "Test minimum sample size per joint group: 30056\n",
      "Undersampled Test shape: (60112, 21)\n",
      "New joint counts:\n",
      " is_spoiler\n",
      "False    30056\n",
      "True     30056\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_99/2103583486.py:23: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  undersampled_test = test.groupby(['is_spoiler']).apply(\n"
     ]
    }
   ],
   "source": [
    "# Check the original distribution of the combined groups\n",
    "group_counts = train.groupby(['is_spoiler']).size()\n",
    "print(\"Original joint counts:\\n\", group_counts)\n",
    "\n",
    "# Determine the minimum and maximum size for balancing all groups\n",
    "min_group_size = group_counts.min()\n",
    "max_group_size = group_counts.max()\n",
    "print(f\"\\nTarget minimum sample size per joint group: {min_group_size}\")\n",
    "print(f\"\\nTarget maximum sample size per joint group: {max_group_size}\")\n",
    "\n",
    "# Undersample each train group to the minimum size found\n",
    "undersampled_train = train.groupby(['is_spoiler']).apply(\n",
    "    lambda x: x.sample(n=min_group_size, replace=False, random_state=3244)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"Undersampled Train shape:\", undersampled_train.shape)\n",
    "print(\"New joint counts:\\n\", undersampled_train.groupby(['is_spoiler']).size())\n",
    "\n",
    "# Undersample each test group to the minimum size found\n",
    "test_group_counts = test.groupby(['is_spoiler']).size()\n",
    "test_min_group_size = test_group_counts.min()\n",
    "print(f\"\\nTest minimum sample size per joint group: {test_min_group_size}\")\n",
    "undersampled_test = test.groupby(['is_spoiler']).apply(\n",
    "    lambda x: x.sample(n=test_min_group_size, replace=False, random_state=3244)\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"Undersampled Test shape:\", undersampled_test.shape)\n",
    "print(\"New joint counts:\\n\", undersampled_test.groupby(['is_spoiler']).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes (naive approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T12:49:07.115394Z",
     "iopub.status.busy": "2025-11-30T12:49:07.114273Z",
     "iopub.status.idle": "2025-11-30T12:57:31.394924Z",
     "shell.execute_reply": "2025-11-30T12:57:31.393737Z",
     "shell.execute_reply.started": "2025-11-30T12:49:07.115357Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# prepare data\n",
    "undersampled_train[\"is_spoiler\"] = undersampled_train[\"is_spoiler\"].astype(int)\n",
    "undersampled_test[\"is_spoiler\"] = undersampled_test[\"is_spoiler\"].astype(int)\n",
    "\n",
    "train1_X = undersampled_train[\"review_text\"].fillna(\"\")\n",
    "train1_y = undersampled_train[\"is_spoiler\"]\n",
    "\n",
    "test1_X = undersampled_test['review_text'].fillna(\"\")\n",
    "test1_y = undersampled_test['is_spoiler']\n",
    "\n",
    "# vectorise\n",
    "tfidf1 = TfidfVectorizer(max_features=150000, ngram_range=(1,3))\n",
    "train1_X_tfidf = tfidf1.fit_transform(train1_X)\n",
    "test1_X_tfidf = tfidf1.transform(test1_X)\n",
    "\n",
    "# fitting model\n",
    "m1 = MultinomialNB()\n",
    "m1.fit(train1_X_tfidf, train1_y)\n",
    "\n",
    "# prediction\n",
    "y_pred1 = m1.predict(test1_X_tfidf)\n",
    "y_pred_prob1 = m1.predict_proba(test1_X_tfidf)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T13:03:55.736662Z",
     "iopub.status.busy": "2025-11-30T13:03:55.735738Z",
     "iopub.status.idle": "2025-11-30T13:03:55.943088Z",
     "shell.execute_reply": "2025-11-30T13:03:55.942216Z",
     "shell.execute_reply.started": "2025-11-30T13:03:55.736629Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6727\n",
      "Precision: 0.6732\n",
      "Recall: 0.6711\n",
      "F1-score: 0.6722\n",
      "F2-score: 0.6716\n",
      "ROC AUC: 0.7330\n",
      "Average Precision (AP): 0.7315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67     30056\n",
      "           1       0.67      0.67      0.67     30056\n",
      "\n",
      "    accuracy                           0.67     60112\n",
      "   macro avg       0.67      0.67      0.67     60112\n",
      "weighted avg       0.67      0.67      0.67     60112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print evaluation metrices\n",
    "acc1 = accuracy_score(test1_y, y_pred1)\n",
    "prec1 = precision_score(test1_y, y_pred1)\n",
    "rec1 = recall_score(test1_y, y_pred1)\n",
    "f1_1 = f1_score(test1_y, y_pred1)\n",
    "f2_1 = fbeta_score(test1_y, y_pred1, beta=2)\n",
    "roc1 = roc_auc_score(test1_y, y_pred_prob1)\n",
    "aps1 = average_precision_score(test1_y, y_pred_prob1)\n",
    "\n",
    "print(f\"Accuracy: {acc1:.4f}\")\n",
    "print(f\"Precision: {prec1:.4f}\")\n",
    "print(f\"Recall: {rec1:.4f}\")\n",
    "print(f\"F1-score: {f1_1:.4f}\")\n",
    "print(f\"F2-score: {f2_1:.4f}\")\n",
    "print(f\"ROC AUC: {roc1:.4f}\")\n",
    "print(f\"Average Precision (AP): {aps1:.4f}\")\n",
    "print(classification_report(test1_y, y_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T13:08:45.373623Z",
     "iopub.status.busy": "2025-11-30T13:08:45.372648Z",
     "iopub.status.idle": "2025-11-30T13:08:45.395147Z",
     "shell.execute_reply": "2025-11-30T13:08:45.394297Z",
     "shell.execute_reply.started": "2025-11-30T13:08:45.373588Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[20264,  9792],\n",
       "       [ 9884, 20172]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test1_y, y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes + Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-30T14:19:10.225206Z",
     "iopub.status.busy": "2025-11-30T14:19:10.224712Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "undersampled_train[\"is_spoiler\"] = undersampled_train[\"is_spoiler\"].astype(int)\n",
    "undersampled_test[\"is_spoiler\"] = undersampled_test[\"is_spoiler\"].astype(int)\n",
    "undersampled_train[\"review_text\"] = undersampled_train[\"review_text\"].fillna(\"\").astype(str)\n",
    "undersampled_train[\"plot_synopsis\"] = undersampled_train[\"plot_synopsis\"].fillna(\"\").astype(str)\n",
    "undersampled_test[\"review_text\"] = undersampled_test[\"review_text\"].fillna(\"\").astype(str)\n",
    "undersampled_test[\"plot_synopsis\"] = undersampled_test[\"plot_synopsis\"].fillna(\"\").astype(str)\n",
    "\n",
    "# vectorise review_text and plot_synopsis \n",
    "tfidf2 = TfidfVectorizer(max_features=150000, ngram_range=(1,3))\n",
    "temp = pd.concat([train['review_text'], train['plot_synopsis']], ignore_index=True)\n",
    "tfidf2.fit(temp) # all vectors use the same vocab\n",
    "\n",
    "train_rev = tfidf2.transform(undersampled_train['review_text'])\n",
    "train_plot = tfidf2.transform(undersampled_train['plot_synopsis'])\n",
    "\n",
    "test_rev = tfidf2.transform(undersampled_test['review_text'])\n",
    "test_plot = tfidf2.transform(undersampled_test['plot_synopsis'])\n",
    "\n",
    "# calculate cosine similiarity for train and test\n",
    "train_cos = []\n",
    "for i in range(len(train)):\n",
    "    sim = cosine_similarity(train_rev[i], train_plot[i])[0][0]\n",
    "    train_cos.append(sim)\n",
    "\n",
    "train['cos_sim'] = train_cos\n",
    "\n",
    "test_cos = []\n",
    "for j in range(len(test)):\n",
    "    sim = cosine_similarity(test_rev[j], test_plot[j])[0][0]\n",
    "    test_cos.append(sim)\n",
    "\n",
    "test['cos_sim'] = test_cos\n",
    "\n",
    "# use both review_text and cosine_feature as features\n",
    "train_cos_score = np.array(train['cos_sim']).reshape(-1, 1)\n",
    "train2_X = hstack([train_rev, train_cos_score])\n",
    "train2_y = train['is_spoiler']\n",
    "\n",
    "test_cos_score = np.array(test['cos_sim']).reshape(-1, 1)\n",
    "test2_X = hstack([test_rev, test_cos_score])\n",
    "test2_y = test['is_spoiler']\n",
    "\n",
    "# fitting model \n",
    "m2 = MultinomialNB()\n",
    "m2.fit(train2_X, train2_y)\n",
    "\n",
    "# prediction\n",
    "y_pred2 = m2.predict(test2_X)\n",
    "y_pred_prob2 = m2.predict_proba(test2_X)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print evaluation metrices\n",
    "acc2 = accuracy_score(test2_y, y_pred2)\n",
    "prec2 = precision_score(test2_y, y_pred2)\n",
    "rec2 = recall_score(test2_y, y_pred2)\n",
    "f1_2 = f1_score(test2_y, y_pred2)\n",
    "f2_2 = fbeta_score(test2_y, y_pred2, beta=2)\n",
    "roc2 = roc_auc_score(test2_y, y_pred_prob2)\n",
    "aps2 = average_precision_score(test2_y, y_pred_prob2)\n",
    "\n",
    "print(f\"Accuracy: {acc2:.4f}\")\n",
    "print(f\"Precision: {prec2:.4f}\")\n",
    "print(f\"Recall: {rec2:.4f}\")\n",
    "print(f\"F1-score: {f1_2:.4f}\")\n",
    "print(f\"F2-score: {f2_2:.4f}\")\n",
    "print(f\"ROC AUC: {roc2:.4f}\")\n",
    "print(f\"Average Precision (AP): {aps2:.4f}\")\n",
    "print(classification_report(test2_y, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(test2_y, y_pred2)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8811441,
     "sourceId": 13835422,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8842844,
     "sourceId": 13879507,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
